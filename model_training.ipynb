{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44597638",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba70c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c77587dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), \n",
    "    transforms.ToTensor(),      \n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a680ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987120cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1) \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # image size\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 output classes \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 16 * 16) \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "        \n",
    "\n",
    "def train_model(model, train_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to('cpu'), labels.to('cpu')\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to('cpu'), labels.to('cpu')\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "def visualize_predictions(model, test_loader):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images, labels = images.to('cpu'), labels.to('cpu')\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5) \n",
    "        plt.title(f\"True: {labels[i].item()}, Pred: {predicted[i].item()}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c689e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets: All Original Images\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)  \n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transform)   \n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7eebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1797\n",
      "Epoch [2/10], Loss: 0.5302\n",
      "Epoch [3/10], Loss: 0.3015\n",
      "Epoch [4/10], Loss: 0.2006\n",
      "Epoch [5/10], Loss: 0.1793\n",
      "Epoch [6/10], Loss: 0.1256\n",
      "Epoch [7/10], Loss: 0.1150\n",
      "Epoch [8/10], Loss: 0.0542\n",
      "Epoch [9/10], Loss: 0.0822\n",
      "Epoch [10/10], Loss: 0.0421\n",
      "Accuracy: 94.55%\n"
     ]
    }
   ],
   "source": [
    "# Model for All Original Images\n",
    "\n",
    "model = CNN()     \n",
    "model.apply(init_weights)\n",
    "    \n",
    "train_model(model, train_loader)\n",
    "evaluate_model(model, test_loader)\n",
    "#visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60a710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "818a0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets: All Synthetic Images\n",
    "\n",
    "train_dataset2 = datasets.ImageFolder(root='syn_img', transform=transform)   \n",
    "train_loader2 = DataLoader(dataset=train_dataset2, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d5852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0142\n",
      "Epoch [2/10], Loss: 0.4824\n",
      "Epoch [3/10], Loss: 0.2014\n",
      "Epoch [4/10], Loss: 0.1336\n",
      "Epoch [5/10], Loss: 0.0784\n",
      "Epoch [6/10], Loss: 0.0488\n",
      "Epoch [7/10], Loss: 0.0471\n",
      "Epoch [8/10], Loss: 0.0309\n",
      "Epoch [9/10], Loss: 0.0562\n",
      "Epoch [10/10], Loss: 0.0476\n",
      "Accuracy: 90.91%\n"
     ]
    }
   ],
   "source": [
    "# Model for All Synthetic Images\n",
    "\n",
    "model2 = CNN()     \n",
    "model2.apply(init_weights)\n",
    "    \n",
    "train_model(model2, train_loader2)\n",
    "evaluate_model(model2, test_loader)\n",
    "#visualize_predictions(model2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd9bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb99f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "523fb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets: Synthetic Images 50% Original 50%\n",
    "\n",
    "syn_img_path = 'syn_img'\n",
    "original_img_path = 'train'\n",
    "\n",
    "synthetic_dataset = datasets.ImageFolder(root=syn_img_path, transform=transform)\n",
    "original_dataset = datasets.ImageFolder(root=original_img_path, transform=transform)\n",
    "\n",
    "def get_class_indices(dataset):\n",
    "    \"\"\"Return a dictionary with class indices grouped by category.\"\"\"\n",
    "    class_indices = {class_name: [] for class_name in dataset.classes}\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_name = dataset.classes[label]\n",
    "        class_indices[class_name].append(idx)\n",
    "    return class_indices\n",
    "\n",
    "synthetic_indices = get_class_indices(synthetic_dataset)\n",
    "original_indices = get_class_indices(original_dataset)\n",
    "\n",
    "def sample_indices(synthetic_indices, original_indices, syn_ratio=0.5, orig_ratio=0.5):\n",
    "    combined_indices = []\n",
    "    for category in synthetic_indices.keys():\n",
    "        syn_count = int(len(synthetic_indices[category]) * syn_ratio)\n",
    "        orig_count = int(len(original_indices[category]) * orig_ratio)\n",
    "\n",
    "        syn_sample = random.sample(synthetic_indices[category], min(syn_count, len(synthetic_indices[category])))\n",
    "        orig_sample = random.sample(original_indices[category], min(orig_count, len(original_indices[category])))\n",
    "\n",
    "        combined_indices.extend(syn_sample + orig_sample)\n",
    "\n",
    "    return combined_indices\n",
    "\n",
    "combined_indices = sample_indices(synthetic_indices, original_indices)\n",
    "\n",
    "\n",
    "combined_dataset = Subset(synthetic_dataset + original_dataset, combined_indices)\n",
    "train_loader3 = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd2b2181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4253\n",
      "Epoch [2/10], Loss: 1.0214\n",
      "Epoch [3/10], Loss: 0.6914\n",
      "Epoch [4/10], Loss: 0.4524\n",
      "Epoch [5/10], Loss: 0.2271\n",
      "Epoch [6/10], Loss: 0.1558\n",
      "Epoch [7/10], Loss: 0.1032\n",
      "Epoch [8/10], Loss: 0.0776\n",
      "Epoch [9/10], Loss: 0.0441\n",
      "Epoch [10/10], Loss: 0.0420\n",
      "Accuracy: 70.91%\n"
     ]
    }
   ],
   "source": [
    "# Model for Synthetic Images 50% Original 50%\n",
    "\n",
    "model3 = CNN()     \n",
    "model3.apply(init_weights)\n",
    "    \n",
    "train_model(model3, train_loader3)\n",
    "evaluate_model(model3, test_loader)\n",
    "#visualize_predictions(model3, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea81d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70 % Synthetic 30% Original\n",
    "\n",
    "combined_indices = sample_indices(synthetic_indices, original_indices, syn_ratio=0.7, orig_ratio=0.3)\n",
    "\n",
    "combined_dataset = Subset(synthetic_dataset + original_dataset, combined_indices)\n",
    "train_loader4 = DataLoader(combined_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a464c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.1633\n",
      "Epoch [2/10], Loss: 0.5146\n",
      "Epoch [3/10], Loss: 0.2474\n",
      "Epoch [4/10], Loss: 0.1089\n",
      "Epoch [5/10], Loss: 0.0844\n",
      "Epoch [6/10], Loss: 0.0564\n",
      "Epoch [7/10], Loss: 0.0365\n",
      "Epoch [8/10], Loss: 0.0308\n",
      "Epoch [9/10], Loss: 0.0347\n",
      "Epoch [10/10], Loss: 0.0206\n",
      "Accuracy: 69.09%\n"
     ]
    }
   ],
   "source": [
    "# Model for 70 % Synthetic 30% Original\n",
    "\n",
    "model4 = CNN()     \n",
    "model4.apply(init_weights)\n",
    "    \n",
    "train_model(model4, train_loader4)\n",
    "evaluate_model(model4, test_loader)\n",
    "#visualize_predictions(model3, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ea38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f70717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
